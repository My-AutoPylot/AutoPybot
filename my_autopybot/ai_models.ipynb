{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from http.client import InvalidURL\n",
    "from pathlib import WindowsPath\n",
    "from typing import Dict, List, Union\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Property 'Excel.Application.ScreenUpdating' can not be set.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [4], line 114\u001b[0m\n\u001b[0;32m    112\u001b[0m output_folder \u001b[39m=\u001b[39m \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mC:\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mUsers\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mmrmay\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mOneDrive\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mDesktop\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mExcel Templates\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mOutput\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    113\u001b[0m output_filename \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mANIL3\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m--> 114\u001b[0m excel_apply_template_format_2(raw_data_filepath\u001b[39m=\u001b[39;49m raw_data_filepath, raw_data_sheetname\u001b[39m=\u001b[39;49mraw_data_sheetname, template_filepath\u001b[39m=\u001b[39;49mtemplate_filepath, template_sheetname\u001b[39m=\u001b[39;49mtemplate_sheetname, output_folder\u001b[39m=\u001b[39;49moutput_folder, output_filename\u001b[39m=\u001b[39;49moutput_filename)\n\u001b[0;32m    116\u001b[0m raw_data_filepath \u001b[39m=\u001b[39m \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mC:\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mUsers\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mmrmay\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mOneDrive\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mDesktop\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mExcel Templates\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mRaw Data - Copy\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mPreviousOrdersFlatReport.xlsx\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    117\u001b[0m raw_data_sheetname \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mPreviousOrdersFlatReport\u001b[39m\u001b[39m\"\u001b[39m\n",
      "Cell \u001b[1;32mIn [4], line 54\u001b[0m, in \u001b[0;36mexcel_apply_template_format_2\u001b[1;34m(raw_data_filepath, raw_data_sheetname, template_filepath, template_sheetname, output_folder, output_filename, overwrite_file)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m---> 54\u001b[0m excel\u001b[39m.\u001b[39;49mScreenUpdating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[39m# copy from source\u001b[39;00m\n\u001b[0;32m     57\u001b[0m source \u001b[39m=\u001b[39m excel\u001b[39m.\u001b[39mWorkbooks\u001b[39m.\u001b[39mOpen(raw_data_filepath)\n",
      "File \u001b[1;32mc:\\Users\\mrmay\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\my-autopybot-ixQ8qYcm-py3.10\\lib\\site-packages\\win32com\\client\\dynamic.py:707\u001b[0m, in \u001b[0;36mCDispatch.__setattr__\u001b[1;34m(self, attr, value)\u001b[0m\n\u001b[0;32m    705\u001b[0m         \u001b[39mexcept\u001b[39;00m pythoncom\u001b[39m.\u001b[39mcom_error:\n\u001b[0;32m    706\u001b[0m             \u001b[39mpass\u001b[39;00m\n\u001b[1;32m--> 707\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\n\u001b[0;32m    708\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mProperty \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m can not be set.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_username_, attr)\n\u001b[0;32m    709\u001b[0m )\n",
      "\u001b[1;31mAttributeError\u001b[0m: Property 'Excel.Application.ScreenUpdating' can not be set."
     ]
    }
   ],
   "source": [
    "from typing import Dict, List, Union\n",
    "from pathlib import WindowsPath\n",
    "def excel_apply_template_format_2(raw_data_filepath:Union[str, WindowsPath], raw_data_sheetname: str = \"Sheet1\", template_filepath:Union[str, WindowsPath] = \"\", template_sheetname: str = \"Sheet1\", output_folder:Union[str, WindowsPath] = \"\", output_filename: str = \"\", overwrite_file = True) -> None: #write_to_same_file: bool = False\n",
    "\n",
    "    # Import Section\n",
    "    import pandas as pd\n",
    "    # from win32com.client import Dispatch\n",
    "    import win32com.client as w3c\n",
    "    import os\n",
    "    \n",
    "    \n",
    "    # Validation section\n",
    "    if not os.path.isfile(raw_data_filepath):\n",
    "        raise FileNotFoundError(f'File not found: {raw_data_filepath}')\n",
    "    \n",
    "    if not os.path.isfile(template_filepath):\n",
    "        raise FileNotFoundError(f'File not found: {template_filepath}')\n",
    "\n",
    "    #check if .xlsx in filename\n",
    "    if not output_filename.endswith(\".xlsx\"):\n",
    "        output_filename = output_filename + \".xlsx\"\n",
    "\n",
    "    output_file_path = os.path.join(output_folder, output_filename)\n",
    "    # print(output_file_path)\n",
    "\n",
    "    # if overwrite_file:\n",
    "    #     if os.path.isfile(output_file_path):\n",
    "    #         os.remove(output_file_path)\n",
    "        \n",
    "    # Code Section\n",
    "    # excel = Dispatch(\"Excel.Application\")\n",
    "\n",
    "    \n",
    "\n",
    "    from pathlib import Path\n",
    "\n",
    "    try:\n",
    "        excel = w3c.Dispatch('Excel.Application')\n",
    "    except:\n",
    "        try:\n",
    "            excel = w3c.gencache.EnsureDispatch('Excel.Application')\n",
    "        except AttributeError:\n",
    "            f_loc = r'C:\\Users\\mrmay\\AppData\\Local\\Temp\\gen_py'\n",
    "            for f in Path(f_loc):\n",
    "                Path.unlink(f)\n",
    "            Path.rmdir(f_loc)\n",
    "            excel = w3c.gencache.EnsureDispatch('Excel.Application')\n",
    "\n",
    "    try:\n",
    "        excel.Visible = False\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    excel.ScreenUpdating = False\n",
    "\n",
    "    # copy from source\n",
    "    source = excel.Workbooks.Open(raw_data_filepath)\n",
    "\n",
    "    #select worksheet\n",
    "    source_sheet = source.Worksheets(raw_data_sheetname)\n",
    "\n",
    "    #activate worksheet\n",
    "    source_sheet.Activate()\n",
    "\n",
    "    # excel.Range(\"A2:D4\").Select()\n",
    "    excel.ActiveSheet.UsedRange.Select()\n",
    "    excel.Selection.Copy()\n",
    "\n",
    "    # paste (appended) to target\n",
    "    try:\n",
    "        target = excel.Workbooks.open(template_filepath)\n",
    "    except:\n",
    "        target = excel.Workbooks.Open(template_filepath)\n",
    "\n",
    "    #select worksheet\n",
    "\n",
    "    # try:\n",
    "        # ws = target.worksheets(template_sheetname)\n",
    "    # except:\n",
    "    try:\n",
    "        ws = target.Worksheets(template_sheetname)\n",
    "    except:\n",
    "        ws = target.WorkSheets(template_sheetname)\n",
    "\n",
    "    #activate worksheet\n",
    "    ws.Activate()\n",
    "\n",
    "    destrange = \"A\"+str(1) #+\":C9\"\n",
    "    \n",
    "    excel.Range(destrange).Select()\n",
    "    excel.Selection.PasteSpecial()\n",
    "\n",
    "    # save and close\n",
    "    shell = w3c.Dispatch(\"WScript.Shell\")\n",
    "    shell.SendKeys(\"{ENTER}\", 0)\n",
    "\n",
    "    excel.Selection.Columns.AutoFit()\n",
    "\n",
    "    excel.ScreenUpdating = True\n",
    "        \n",
    "    ws.SaveAs(output_file_path, 51) # 51 = excel format\n",
    "        \n",
    "    target.Close()\n",
    "\n",
    "    source.Close()\n",
    "    excel.Quit()\n",
    "\n",
    "raw_data_filepath = r\"C:\\Users\\mrmay\\OneDrive\\Desktop\\Excel Templates\\Raw Data - Copy\\PreviousMobileOrdersFlatReport.xlsx\"\n",
    "raw_data_sheetname = \"PreviousMobileOrdersFlatReport\"\n",
    "template_filepath = r\"C:\\Users\\mrmay\\OneDrive\\Desktop\\Excel Templates\\Master Template - Copy\\Master - Copy.xlsx\"\n",
    "template_sheetname= \"Mobile Sales Detail\"\n",
    "output_folder = r\"C:\\Users\\mrmay\\OneDrive\\Desktop\\Excel Templates\\Output\"\n",
    "output_filename = \"ANIL3\"\n",
    "excel_apply_template_format_2(raw_data_filepath= raw_data_filepath, raw_data_sheetname=raw_data_sheetname, template_filepath=template_filepath, template_sheetname=template_sheetname, output_folder=output_folder, output_filename=output_filename)\n",
    "\n",
    "raw_data_filepath = r\"C:\\Users\\mrmay\\OneDrive\\Desktop\\Excel Templates\\Raw Data - Copy\\PreviousOrdersFlatReport.xlsx\"\n",
    "raw_data_sheetname = \"PreviousOrdersFlatReport\"\n",
    "template_filepath = os.path.join(output_folder, output_filename + \".xlsx\")\n",
    "template_sheetname= \"Core Sales Details\"\n",
    "output_folder = r\"C:\\Users\\mrmay\\OneDrive\\Desktop\\Excel Templates\\Output\"\n",
    "output_filename = \"ANIL4\"\n",
    "\n",
    "\n",
    "excel_apply_template_format_2(raw_data_filepath= raw_data_filepath, raw_data_sheetname=raw_data_sheetname, template_filepath=template_filepath, template_sheetname=template_sheetname, output_folder=output_folder, output_filename=output_filename, overwrite_file=False)\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to iterate through dataframe by row and column\n",
    "\n",
    "excel_path = r\"C:\\Users\\mrmay\\OneDrive\\Desktop\\Excel Templates\\PreviousOrdersFlatReport.xlsx\"\n",
    "\n",
    "def loop_through_excel_by_specific_column(excel_path,sheet_name, column_name):\n",
    "    import pandas as pd\n",
    "    df = pd.read_excel(excel_path, sheet_name=sheet_name, usecols=[column_name])\n",
    "\n",
    "    #remove duplicates\n",
    "    df = df.drop_duplicates()\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        print(row[0])    \n",
    "\n",
    "loop_through_excel_by_specific_column(excel_path, 'PreviousOrdersFlatReport', 'MSO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def excel_group_by_column_values_n_split(df, column_name=\"\", output_folder=\"\"):\n",
    "    # import section\n",
    "    import pandas as pd\n",
    "    from pathlib import Path\n",
    "    import os\n",
    "\n",
    "    try:\n",
    "        \n",
    "        if not column_name:\n",
    "            raise Exception(\"Please provide the column name to split.\")\n",
    "        if not output_folder:\n",
    "            raise Exception(\"Please provide the output folder path.\")\n",
    "        \n",
    "        grouped_df = df.groupby(column_name)\n",
    "\n",
    "        # for i in grouped_df:\n",
    "        #     print(i[0])\n",
    "\n",
    "        for i in grouped_df:\n",
    "            file_name = str(i[0]) + \".xlsx\"\n",
    "            file_name = output_folder + \"\\\\\" + file_name\n",
    "            grouped_df.get_group(i[0]).to_excel(file_name, index=False)\n",
    "\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "excel_path = r\"C:\\Users\\mrmay\\OneDrive\\Desktop\\Excel Templates\\PreviousOrdersFlatReport.xlsx\"\n",
    "df = pd.read_excel(excel_path, sheet_name='PreviousOrdersFlatReport')\n",
    "\n",
    "excel_group_by_column_values_n_split(df, column_name=\"Affiliate\", output_folder=r\"C:\\Users\\mrmay\\OneDrive\\Desktop\\Excel Templates\\Split\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'es'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def detect_language(text : str) -> str:\n",
    "    \"\"\"\n",
    "    Description: Detects the language of the text\n",
    "\n",
    "    Parameters:\n",
    "    text (str): Text to detect the language\n",
    "\n",
    "    Returns:\n",
    "    str: Language of the text\n",
    "\n",
    "    Example:\n",
    "    >>> detect_language(\"Hello World\")\n",
    "    'en'\n",
    "\n",
    "    \"\"\"\n",
    "    # Import section\n",
    "    from langdetect import detect\n",
    "\n",
    "    # Code section\n",
    "    try:\n",
    "        return detect(text)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# detect_language(\"War doesn't show who's right, just who's left.\")\n",
    "detect_language(\"La guerra no muestra quién tiene la razón, solo quién queda.\")\n",
    "# detect_language(\"ಸಾಧನಕೇರಿ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[en:0.9999975401282177]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def detect_language_with_prob(text : str):\n",
    "    \"\"\"\n",
    "    Description: Detects the language of the text with probability\n",
    "\n",
    "    Parameters:\n",
    "    text (str): Text to detect the language\n",
    "\n",
    "    Returns:\n",
    "    str: Language of the text\n",
    "\n",
    "    Example:\n",
    "    >>> detect_language(\"Hello World\")\n",
    "    'en'\n",
    "\n",
    "    \"\"\"\n",
    "    # Import section\n",
    "    from langdetect import detect_langs\n",
    "\n",
    "    # Code section\n",
    "    try:\n",
    "        return detect_langs(text)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "detect_language_with_prob(\"War doesn't show who's right, just who's left.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kn\n"
     ]
    }
   ],
   "source": [
    "def detect_choose_among_languages(text:str, languages: list):\n",
    "    \"\"\"\n",
    "    Description: Detects and chooses the language among the languages provided\n",
    "\n",
    "    Parameters:\n",
    "    text (str): Text to detect the language\n",
    "    languages (list): List of languages to choose from\n",
    "\n",
    "    Returns:\n",
    "    str: Language of the text\n",
    "\n",
    "    Example:\n",
    "    >>> detect_choose_among_languages(\"Hello World\", ['en', 'fr'])\n",
    "    'en'\n",
    "\n",
    "    \"\"\"\n",
    "    # Import section\n",
    "    from langdetect import detect_langs\n",
    "\n",
    "    # Code section\n",
    "    try:\n",
    "        detected_langs = detect_langs(text)\n",
    "        for lang in detected_langs:\n",
    "            if lang.lang in languages:\n",
    "                return lang.lang\n",
    "        return None\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# print(detect_choose_among_languages(\"La guerra no muestra quién tiene la razón, solo quién queda.\", [\"en\", \"fr\", \"de\"])) #es\n",
    "print(detect_choose_among_languages(\"ಸಾಧನಕೇರಿ\", [\"en\", \"fr\", \"de\", \"kn\"])) #None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'group'\n"
     ]
    }
   ],
   "source": [
    "# #function to translate text from one language to another\n",
    "# #using googletrans library\n",
    "# #pip install googletrans\n",
    "\n",
    "# def text_translate(text:str, dest_lang:str, src_lang:str=\"\"):\n",
    "#     \"\"\"\n",
    "#     Description: Translates the text from source language to destination language\n",
    "\n",
    "#     Parameters:\n",
    "#     text (str): Text to translate\n",
    "#     dest_lang (str): Destination language to translate to\n",
    "#     src_lang (str): Source language to translate from\n",
    "\n",
    "#     Returns:\n",
    "#     str: Translated text\n",
    "\n",
    "#     Example:\n",
    "#     >>> text_translate(\"Hello World\", \"fr\")\n",
    "#     'Bonjour le monde'\n",
    "\n",
    "#     \"\"\"\n",
    "#     # Import section\n",
    "#     from googletrans import Translator\n",
    "\n",
    "#     # Code section\n",
    "#     try:\n",
    "#         # translator = Translator()\n",
    "#         translator = Translator(service_urls=['translate.googleapis.com'])\n",
    "#         # if src_lang:\n",
    "#         #     return translator.translate(text, dest=dest_lang, src=src_lang).text\n",
    "#         # else:\n",
    "#         result = translator.translate(text, dest=dest_lang)\n",
    "#         return result.text\n",
    "#     except Exception as ex:\n",
    "#         print(ex)\n",
    "#         return None\n",
    "        \n",
    "\n",
    "# text_translate(\"Hello World\",\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Negative'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def text_classify_pos_neg(text : str) -> str:\n",
    "    \"\"\"\n",
    "    Description: Classifies the text as positive or negative\n",
    "\n",
    "    Parameters:\n",
    "    text (str): Text to classify\n",
    "\n",
    "    Returns:\n",
    "    str: Positive or Negative\n",
    "\n",
    "    Example:\n",
    "    >>> text_classify_pos_neg(\"I love this product\")\n",
    "    'Positive'\n",
    "\n",
    "    \"\"\"\n",
    "    # Import section\n",
    "    from textblob import TextBlob\n",
    "\n",
    "    # Code section\n",
    "    try:\n",
    "        polarity = TextBlob(text).sentiment.polarity\n",
    "        if polarity > 0:\n",
    "            return \"Positive\"\n",
    "        elif polarity < 0:\n",
    "            return \"Negative\"\n",
    "        else:\n",
    "            return \"Neutral\"\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "text_classify_pos_neg(\"I do not enjoy my job\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pos'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def text_classify_with_training(text : str, training_data : list = \"\") -> str:\n",
    "    \"\"\"\n",
    "    Description: Classifies the text as positive or negative\n",
    "\n",
    "    Parameters:\n",
    "    text (str): Text to classify\n",
    "    training_data (list): Training data to train the classifier\n",
    "\n",
    "    Returns:\n",
    "    str: Positive or Negative\n",
    "\n",
    "    Example:\n",
    "    >>> text_classify_with_training(\"I love this product\", [[\"I love this product\", \"Positive\"], [\"I hate this product\", \"Negative\"]])\n",
    "    'Positive'\n",
    "\n",
    "    \"\"\"\n",
    "    if not training_data:\n",
    "        training_data = [\n",
    "            ('I love this sandwich.', 'pos'),\n",
    "            ('this is an amazing place!', 'pos'),\n",
    "            ('I feel very good about these beers.', 'pos'),\n",
    "            ('this is my best work.', 'pos'),\n",
    "            (\"what an awesome view\", 'pos'),\n",
    "            ('I do not like this restaurant', 'neg'),\n",
    "            ('I am tired of this stuff.', 'neg'),\n",
    "            (\"I can't deal with this\", 'neg'),\n",
    "            ('he is my sworn enemy!', 'neg'),\n",
    "            ('my boss is horrible.', 'neg')\n",
    "        ]\n",
    "        test = [\n",
    "            ('the beer was good.', 'pos'),\n",
    "            ('I do not enjoy my job', 'neg'),\n",
    "            (\"I ain't feeling dandy today.\", 'neg'),\n",
    "            (\"I feel amazing!\", 'pos'),\n",
    "            ('Gary is a friend of mine.', 'pos'),\n",
    "            (\"I can't believe I'm doing this.\", 'neg')\n",
    "        ]\n",
    "\n",
    "    # Import section\n",
    "    from textblob.classifiers import NaiveBayesClassifier\n",
    "\n",
    "    # Code section\n",
    "    try:\n",
    "        classifier = NaiveBayesClassifier(training_data)\n",
    "        return classifier.classify(text)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "text_classify_with_training(\"I love this sandwich.\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download en_core_web_sm #one time for download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Apple', 'ORG'), ('U.K.', 'GPE'), ('$1 billion', 'MONEY')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_named_entities_for_given_text(text : str) -> list:\n",
    "    \"\"\"\n",
    "    Description: Gets the named entities from the text\n",
    "\n",
    "    Parameters:\n",
    "    text (str): Text to get the named entities from\n",
    "\n",
    "    Returns:\n",
    "    list: List of named entities\n",
    "\n",
    "    Example:\n",
    "    >>> get_named_entities(\"I love New York\")\n",
    "    ['New York']\n",
    "\n",
    "    \"\"\"\n",
    "    # Import section\n",
    "    import spacy\n",
    "\n",
    "    # Code section\n",
    "    try:\n",
    "        nlp = spacy.load('en_core_web_sm')\n",
    "        doc = nlp(text)\n",
    "        return [(X.text, X.label_) for X in doc.ents]\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# get_named_entities_for_given_text(\"I am from India and I live in New York\")\n",
    "get_named_entities_for_given_text(\"Apple is looking at buying U.K. startup for $1 billion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 'PRON'), ('love', 'VERB'), ('New', 'PROPN'), ('York', 'PROPN')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Part-of-speech Tagging\n",
    "\n",
    "def text_pos_tag_spacy(text : str) -> list:\n",
    "    \"\"\"\n",
    "    Description: Gets the part of speech tags from the text\n",
    "\n",
    "    Parameters:\n",
    "    text (str): Text to get the part of speech tags from\n",
    "\n",
    "    Returns:\n",
    "    list: List of part of speech tags\n",
    "\n",
    "    Example:\n",
    "    >>> text_pos_tag(\"I love New York\")\n",
    "    [('I', 'PRP'), ('love', 'VBP'), ('New', 'NNP'), ('York', 'NNP')]\n",
    "\n",
    "    \"\"\"\n",
    "    # Import section\n",
    "    import spacy\n",
    "\n",
    "    # Code section\n",
    "    try:\n",
    "        nlp = spacy.load('en_core_web_sm')\n",
    "        doc = nlp(text)\n",
    "        return [(X.text, X.pos_) for X in doc]\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "text_pos_tag_spacy(\"I love New York\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 'PRP'), ('love', 'VBP'), ('New', 'NNP'), ('York', 'NNP')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Part-of-speech Tagging\n",
    "\n",
    "def text_pos_tag_textblob(text : str) -> list:\n",
    "    \"\"\"\n",
    "    Description: Gets the part of speech tags from the text\n",
    "\n",
    "    Parameters:\n",
    "    text (str): Text to get the part of speech tags from\n",
    "\n",
    "    Returns:\n",
    "    list: List of part of speech tags\n",
    "\n",
    "    Example:\n",
    "    >>> text_pos_tag(\"I love New York\")\n",
    "    [('I', 'PRP'), ('love', 'VBP'), ('New', 'NNP'), ('York', 'NNP')]\n",
    "\n",
    "    \"\"\"\n",
    "    # Import section\n",
    "    from textblob import TextBlob\n",
    "\n",
    "    # Code section\n",
    "    try:\n",
    "        return TextBlob(text).tags\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "text_pos_tag_textblob(\"I love New York\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['nlp'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#text_noun_phrases extraction\n",
    "\n",
    "def text_noun_phrases(text : str) -> list:\n",
    "    \"\"\"\n",
    "    Description: Gets the noun phrases from the text\n",
    "\n",
    "    Parameters:\n",
    "    text (str): Text to get the noun phrases from\n",
    "\n",
    "    Returns:\n",
    "    list: List of noun phrases\n",
    "\n",
    "    Example:\n",
    "    >>> text_noun_phrases(\"I love New York\")\n",
    "    ['I', 'New York']\n",
    "\n",
    "    \"\"\"\n",
    "    # Import section\n",
    "    from textblob import TextBlob\n",
    "\n",
    "    # Code section\n",
    "    try:\n",
    "        return TextBlob(text).noun_phrases\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "text_noun_phrases(\"I am learning NLP\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.3181818181818182, subjectivity=0.5272727272727272)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sentiment Analysis\n",
    "def text_sentiment_analysis(text : str) -> str:\n",
    "    \"\"\"\n",
    "    Description: Gets the sentiment analysis from the text\n",
    "\n",
    "    Parameters:\n",
    "    text (str): Text to get the sentiment analysis from\n",
    "\n",
    "    Returns:\n",
    "    str: Sentiment analysis\n",
    "\n",
    "    Example:\n",
    "    >>> text_sentiment_analysis(\"I love New York\")\n",
    "    Sentiment(polarity=0.8, subjectivity=1.0)\n",
    "    \n",
    "    \"\"\"\n",
    "    # Import section\n",
    "    from textblob import TextBlob\n",
    "\n",
    "    # Code section\n",
    "    try:\n",
    "        blob = TextBlob(text)\n",
    "        return blob.sentiment   \n",
    "    except:\n",
    "        return None\n",
    "\n",
    "text_sentiment_analysis(\"I love New York\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Sentence(\"I am learning NLP.\"),\n",
       " Sentence(\"It is fun to learn.\"),\n",
       " Sentence(\"I wish to learn more about NLP.\")]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def text_break_into_sentenses(text : str) -> list:\n",
    "    \"\"\"\n",
    "    Description: Breaks the text into sentenses\n",
    "\n",
    "    Parameters:\n",
    "    text (str): Text to break into sentenses\n",
    "\n",
    "    Returns:\n",
    "    list: List of sentenses\n",
    "\n",
    "    Example:\n",
    "    >>> text_break_into_sentenses(\"I love New York. I love Paris\")\n",
    "    ['I love New York', 'I love Paris']\n",
    "    \n",
    "    \"\"\"\n",
    "    # Import section\n",
    "    from textblob import TextBlob\n",
    "\n",
    "    # Code section\n",
    "    try:\n",
    "        blob = TextBlob(text)\n",
    "        return blob.sentences   \n",
    "    except:\n",
    "        return None\n",
    "\n",
    "text_break_into_sentenses(\"I am learning NLP. It is fun to learn. I wish to learn more about NLP.\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Sentence(\"I am learning NLP.\"), Sentiment(polarity=0.0, subjectivity=0.0)),\n",
       " (Sentence(\"It is fun to learn.\"), Sentiment(polarity=0.3, subjectivity=0.2)),\n",
       " (Sentence(\"I wish to learn more about NLP.\"),\n",
       "  Sentiment(polarity=0.5, subjectivity=0.5))]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def text_break_into_sentense_perform_senti_analysis(text : str) -> list:\n",
    "    \"\"\"\n",
    "    Description: Breaks the text into sentenses and performs sentiment analysis\n",
    "\n",
    "    Parameters:\n",
    "    text (str): Text to break into sentenses and perform sentiment analysis\n",
    "\n",
    "    Returns:\n",
    "    list: List of sentenses and sentiment analysis\n",
    "\n",
    "    Example:\n",
    "    >>> text_break_into_sentense_perform_senti_analysis(\"I love New York. I love Paris\")\n",
    "    [('I love New York', Sentiment(polarity=0.8, subjectivity=1.0)), ('I love Paris', Sentiment(polarity=0.8, subjectivity=1.0))]\n",
    "    \n",
    "    \"\"\"\n",
    "    # Import section\n",
    "    from textblob import TextBlob\n",
    "\n",
    "    # Code section\n",
    "    try:\n",
    "        blob = TextBlob(text)\n",
    "        return [(sentence, sentence.sentiment) for sentence in blob.sentences]   \n",
    "    except:\n",
    "        return None\n",
    "\n",
    "text_break_into_sentense_perform_senti_analysis(\"I am learning NLP. It is fun to learn. I wish to learn more about NLP.\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['I', 'am', 'learning', 'NLP'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def text_break_into_words(text : str) -> list:\n",
    "    \"\"\"\n",
    "    Description: Breaks the text into words\n",
    "\n",
    "    Parameters:\n",
    "    text (str): Text to break into words\n",
    "\n",
    "    Returns:\n",
    "    list: List of words\n",
    "\n",
    "    Example:\n",
    "    >>> text_break_into_words(\"I love New York\")\n",
    "    ['I', 'love', 'New', 'York']\n",
    "    \n",
    "    \"\"\"\n",
    "    # Import section\n",
    "    from textblob import TextBlob\n",
    "\n",
    "    # Code section\n",
    "    try:\n",
    "        blob = TextBlob(text)\n",
    "        return blob.words   \n",
    "    except:\n",
    "        return None\n",
    "\n",
    "text_break_into_words(\"I am learning NLP\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"I am learning NLP\")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def text_spelling_correction(text : str) -> str:\n",
    "    \"\"\"\n",
    "    Description: Corrects the spelling of the text\n",
    "\n",
    "    Parameters:\n",
    "    text (str): Text to correct the spelling\n",
    "\n",
    "    Returns:\n",
    "    str: Corrected text\n",
    "\n",
    "    Example:\n",
    "    >>> text_spelling_correction(\"I love New York\")\n",
    "    'I love New York'\n",
    "    \n",
    "    \"\"\"\n",
    "    # Import section\n",
    "    from textblob import TextBlob\n",
    "\n",
    "    # Code section\n",
    "    try:\n",
    "        blob = TextBlob(text)\n",
    "        return blob.correct()   \n",
    "    except:\n",
    "        return None\n",
    "\n",
    "text_spelling_correction(\"I am learnng NLP\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('have', 1.0)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def word_spelling_correct_prob(text : str) -> dict:\n",
    "    \"\"\"\n",
    "    Description: Gets the probability of the spelling correction of the word\n",
    "\n",
    "    Parameters:\n",
    "    text (str): Word to get the probability of the spelling correction\n",
    "\n",
    "    Returns:\n",
    "    dict: Dictionary of the word and its probability of spelling correction\n",
    "\n",
    "    Example:\n",
    "    >>> word_spelling_correct_prob(\"learnng\")\n",
    "    {'learning': 0.9999999999999999}\n",
    "    \n",
    "    \"\"\"\n",
    "    # Import section\n",
    "    from textblob import Word\n",
    "\n",
    "    # Code section\n",
    "    try:\n",
    "        word = Word(text)\n",
    "        return word.spellcheck()   \n",
    "    except:\n",
    "        return None\n",
    "\n",
    "word_spelling_correct_prob(\"havv\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_word_frequency_textblob(text: str, word : str) -> int:\n",
    "    \"\"\"\n",
    "    Description: Gets the frequency of the word in the text\n",
    "\n",
    "    Parameters:\n",
    "    text (str): Text to get the frequency of the word\n",
    "    word (str): Word to get the frequency of\n",
    "\n",
    "    Returns:\n",
    "    int: Frequency of the word in the text\n",
    "\n",
    "    Example:\n",
    "    >>> get_word_frequency_textblob(\"I love New York\", \"love\")\n",
    "    1\n",
    "    \n",
    "    \"\"\"\n",
    "    # Import section\n",
    "    from textblob import TextBlob\n",
    "\n",
    "    # Code section\n",
    "    try:\n",
    "        blob = TextBlob(text)\n",
    "        return blob.word_counts[word]   \n",
    "    except:\n",
    "        return None\n",
    "\n",
    "get_word_frequency_textblob(\"I am learning NLP. It is fun to learn. I wish to learn more about NLP.\", \"learn\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MRZ(TD2[valid], D23145890, ANNAKMARIA, ERIKSSON, F, 740812)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from passporteye import read_mrz\n",
    "def read_passport(passport_img_file: str):\n",
    "    \"\"\"\n",
    "    Description: Reads the passport image and returns the MRZ\n",
    "\n",
    "    Parameters:\n",
    "    passport_img_file (str): File path of the passport image\n",
    "\n",
    "    Returns:\n",
    "    str: MRZ of the passport\n",
    "\n",
    "    Example:\n",
    "    >>> read_passport(\"passport.jpg\")\n",
    "    MRZ(Type='TD3', country='IND', surname='SINGH', given_names='RAJESH', document_number='123456789\n",
    "\n",
    "    \"\"\"\n",
    "    # Import section\n",
    "    from passporteye import read_mrz\n",
    "\n",
    "    # Code section\n",
    "    try:\n",
    "        return read_mrz(passport_img_file)\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "read_passport(r\"C:\\Users\\mrmay\\OneDrive\\Desktop\\AI Models\\passport-td2.png\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I love New York'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# strip out non-ASCII text \n",
    "def text_cleanup(text : str) -> str:\n",
    "    \"\"\"\n",
    "    Description: Cleans up the text\n",
    "\n",
    "    Parameters:\n",
    "    text (str): Text to clean up\n",
    "\n",
    "    Returns:\n",
    "    str: Cleaned up text\n",
    "\n",
    "    Example:\n",
    "    >>> text_cleanup(\"I love New York\")\n",
    "    'I love New York'\n",
    "    \n",
    "    \"\"\"\n",
    "    # Import section\n",
    "    import re\n",
    "\n",
    "    # Code section\n",
    "    try:\n",
    "        return \"\".join([c if ord(c) < 128 else \"\" for c in text]).strip() \n",
    "    except:\n",
    "        return None\n",
    "\n",
    "text_cleanup(\"I love New York\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[([[18, 21], [377, 21], [377, 148], [18, 148]], 'Because', 0.6187961141954096),\n",
       " ([[39, 163], [395, 163], [395, 278], [39, 278]],\n",
       "  'be doing',\n",
       "  0.47014706541372214)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ocr_easyocr(img_file : str, languages : list = [\"en\"], use_gpu = False) -> str:\n",
    "    \"\"\"\n",
    "    Description: Performs OCR using EasyOCR\n",
    "\n",
    "    Parameters:\n",
    "    img_file (str): File path of the image\n",
    "    languages (list): List of languages to perform OCR\n",
    "\n",
    "    Returns:\n",
    "    str: Text from the image\n",
    "\n",
    "    Example:\n",
    "    >>> ocr_easyocr(\"test.png\")\n",
    "    'I love New York'\n",
    "    \n",
    "    \"\"\"\n",
    "    # Import section\n",
    "    import easyocr\n",
    "    import cv2\n",
    "\n",
    "    # Code section\n",
    "    image = cv2.imread(img_file)\n",
    "    try:\n",
    "        reader = easyocr.Reader(languages, gpu=use_gpu)\n",
    "        return reader.readtext(image)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "ocr_easyocr(r\"C:\\Users\\mrmay\\OneDrive\\Desktop\\AI Models\\htr_img.jpeg\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ocr_easyocr_draw_bouding_box(img_file : str, languages : list = [\"en\"], use_gpu = False) -> str:\n",
    "    \"\"\"\n",
    "    Description: Performs OCR using EasyOCR and draws bounding box around the text\n",
    "\n",
    "    Parameters:\n",
    "    img_file (str): File path of the image\n",
    "    languages (list): List of languages to perform OCR\n",
    "\n",
    "    Returns:\n",
    "    str: Text from the image\n",
    "\n",
    "    Example:\n",
    "    >>> ocr_easyocr_draw_bouding_box(\"test.png\")\n",
    "    'I love New York'\n",
    "    \n",
    "    \"\"\"\n",
    "    # Import section\n",
    "    import easyocr\n",
    "    import cv2\n",
    "\n",
    "    # Code section\n",
    "    image = cv2.imread(img_file)\n",
    "    \n",
    "    reader = easyocr.Reader(languages, gpu=use_gpu)\n",
    "    result = reader.readtext(image)\n",
    "    for detection in result:\n",
    "        top_left = tuple([int(val) for val in detection[0][0]])\n",
    "        bottom_right = tuple([int(val) for val in detection[0][2]])\n",
    "        text = detection[1]\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        image = cv2.rectangle(image, top_left, bottom_right, (0,255,0), 5)\n",
    "        image = cv2.putText(image, text, top_left, font, 0.8, (0,0,255), 2, cv2.LINE_AA)\n",
    "\n",
    "    cv2.imshow('image', image)\n",
    "\n",
    "# ocr_easyocr_draw_bouding_box(r\"C:\\Users\\mrmay\\OneDrive\\Desktop\\AI Models\\htr_img.jpeg\")\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('my-autopybot-ixQ8qYcm-py3.10')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6578dd0914c74309d3dd06ee2782a87c0ce63e419a01b8e8a145bf9ee71dbebc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
